# Web Crawler

This is my first project with Go. I wanted to learn Go after experimenting with multithreading on a previous project (EzNotes, check out my profile) and Go has strong concurrency support. It crawls a list of URL's, using a thread for each URL. It's extremely fast and I was impressed by the language. There's definitely a learning curve but I can see the benefits already.

# Next steps

My next step is to add a functional front end to the project. I think this project could be useful to people, so I'm going to try and give it some polish. We will see though since my react skills are limited. After that, I'm going to host it somewhere and then make a write up on the process that I took. 
